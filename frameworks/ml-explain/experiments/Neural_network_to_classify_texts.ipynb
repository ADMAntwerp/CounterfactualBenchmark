{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total texts in train: 1774\n",
      "total texts in test: 1180\n"
     ]
    }
   ],
   "source": [
    "categories = [\"comp.graphics\",\"sci.space\",\"rec.sport.baseball\"]\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "print('total texts in train:',len(newsgroups_train.data))\n",
    "print('total texts in test:',len(newsgroups_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'rec.sport.baseball', 'sci.space']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# newsgroups_train.target\n",
    "# newsgroups_train.target_names\n",
    "newsgroups_test.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each one is the list of strings\n",
    "data_train, data_test = newsgroups_train.data, newsgroups_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dd1938ac809f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'total_words' is not defined"
     ]
    }
   ],
   "source": [
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in newsgroups_train.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "        \n",
    "for text in newsgroups_test.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "        \n",
    "total_words = len(vocab)\n",
    "\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    index2word = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word.lower()] = i\n",
    "        index2word[i] = word.lower()\n",
    "        \n",
    "    return word2index, index2word\n",
    "\n",
    "word2index, index2word = get_word_2_index(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2bow(texts):\n",
    "    bow = np.zeros((len(texts), total_words))\n",
    "    for text_idx, text in enumerate(texts):\n",
    "        for word in text.split(' '):\n",
    "            bow[text_idx, word2index[word.lower()]] += 1\n",
    "    return bow\n",
    "\n",
    "X_train, X_test = torch.tensor(convert2bow(data_train), dtype=torch.float32), torch.tensor(convert2bow(data_test), dtype=torch.float32)\n",
    "y_train, y_test = newsgroups_train.target, newsgroups_test.target\n",
    "y_train_names, y_test_names = newsgroups_train.target_names, newsgroups_test.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(df,i,batch_size):\n",
    "    batches = []\n",
    "    results = []\n",
    "    texts = df.data[i*batch_size:i*batch_size+batch_size]\n",
    "    categories = df.target[i*batch_size:i*batch_size+batch_size]\n",
    "    for text in texts:\n",
    "        layer = np.zeros(total_words,dtype=float)\n",
    "        for word in text.split(' '):\n",
    "            layer[word2index[word.lower()]] += 1\n",
    "            \n",
    "        batches.append(layer)\n",
    "        \n",
    "    for category in categories:\n",
    "        index_y = -1\n",
    "        if category == 0:\n",
    "            index_y = 0\n",
    "        elif category == 1:\n",
    "            index_y = 1\n",
    "        else:\n",
    "            index_y = 2\n",
    "        results.append(index_y)\n",
    "            \n",
    "     \n",
    "    return np.array(batches),np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 150\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "hidden_size = 100      # 1st layer and 2nd layer number of features\n",
    "input_size = total_words # Words in vocab\n",
    "num_classes = 3         # Categories: graphics, sci.space and baseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurNet(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(OurNet, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_size,hidden_size, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes, bias=True)\n",
    " \n",
    "     def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> batch of size 2 and 5 possible classes\n",
      "tensor([[ 0.2462, -1.0717, -1.9975,  0.3517, -0.2022],\n",
      "        [-0.2601, -0.9926,  2.2672, -1.2531, -1.4651]], requires_grad=True)\n",
      ">>> array of size 'batch_size' with the index of the maxium label for each item\n",
      "tensor([0, 4])\n"
     ]
    }
   ],
   "source": [
    "# input [batch_size, n_labels]\n",
    "# output [max index for each item in batch, ... ,batch_size-1]\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = Variable(torch.randn(2, 5), requires_grad=True)\n",
    "print(\">>> batch of size 2 and 5 possible classes\")\n",
    "print(input)\n",
    "target = Variable(torch.LongTensor(2).random_(5))\n",
    "print(\">>> array of size 'batch_size' with the index of the maxium label for each item\")\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [4/11], Loss: 1.2979\n",
      "Epoch [1/10], Step [8/11], Loss: 0.4154\n",
      "Epoch [2/10], Step [4/11], Loss: 0.0927\n",
      "Epoch [2/10], Step [8/11], Loss: 0.2134\n",
      "Epoch [3/10], Step [4/11], Loss: 0.0609\n",
      "Epoch [3/10], Step [8/11], Loss: 0.0002\n",
      "Epoch [4/10], Step [4/11], Loss: 0.0000\n",
      "Epoch [4/10], Step [8/11], Loss: 0.0000\n",
      "Epoch [5/10], Step [4/11], Loss: 0.0008\n",
      "Epoch [5/10], Step [8/11], Loss: 0.0000\n",
      "Epoch [6/10], Step [4/11], Loss: 0.0000\n",
      "Epoch [6/10], Step [8/11], Loss: 0.0968\n",
      "Epoch [7/10], Step [4/11], Loss: 0.0000\n",
      "Epoch [7/10], Step [8/11], Loss: 0.0000\n",
      "Epoch [8/10], Step [4/11], Loss: 0.0000\n",
      "Epoch [8/10], Step [8/11], Loss: 0.0001\n",
      "Epoch [9/10], Step [4/11], Loss: 0.0002\n",
      "Epoch [9/10], Step [8/11], Loss: 0.0000\n",
      "Epoch [10/10], Step [4/11], Loss: 0.0003\n",
      "Epoch [10/10], Step [8/11], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "net = OurNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    total_batch = int(len(newsgroups_train.data)/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(newsgroups_train,i,batch_size)\n",
    "        articles = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        #print(\"articles\",articles)\n",
    "        #print(batch_x, labels)\n",
    "        #print(\"size labels\",labels.size())\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(articles)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 4 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(newsgroups_train.data)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1180 test articles: 90 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_test_data = len(newsgroups_test.target)\n",
    "batch_x_test,batch_y_test = get_batch(newsgroups_test,0,total_test_data)\n",
    "articles = Variable(torch.FloatTensor(batch_x_test))\n",
    "labels = torch.LongTensor(batch_y_test)\n",
    "outputs = net(articles)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "total += labels.size(0)\n",
    "correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the network on the 1180 test articles: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate set of counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlexplain.sce.util import choose_k_top_elements_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 10 objects and display them\n",
    "X_class_0 = choose_k_top_elements_softmax(net, X_train, K=10, target_class=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlexplain.sce.text_sce import TextSCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1. LR=0.1, lambda_coef=0, mu_coef=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sce = TextSCE(net, target_class=0, index2word=index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] Cost: 318.3843688964844 [318.3843688964844, 0.0, 0.0]\n",
      "[5/30] Cost: 282.36541748046875 [282.36541748046875, 0.0, 0.0]\n",
      "[10/30] Cost: 235.9352264404297 [235.9352264404297, 0.0, 0.0]\n",
      "[15/30] Cost: 187.18814086914062 [187.18814086914062, 0.0, 0.0]\n",
      "[20/30] Cost: 140.813232421875 [140.813232421875, 0.0, 0.0]\n",
      "[25/30] Cost: 90.9652328491211 [90.9652328491211, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlexplain.sce.text_sce.TextSCE at 0x7fe8258eb6a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sce.fit(X_class_0, lambda_coef=0.0, mu_coef=0.0, n_iter=30, verbose_every_iterations=5, lr=0.1, force_masks_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['computer', 'package', 'file', 'card', 'graphics'],\n",
       " ['computer', 'package', 'card', 'file', 'pc'],\n",
       " ['computer', 'package', 'file', 'card', 'pc'],\n",
       " ['computer', 'package', 'card', 'file', 'pc'],\n",
       " ['computer', 'package', 'card', 'file', 'pc'],\n",
       " ['computer', 'package', 'card', 'file', 'anybody'],\n",
       " ['computer', 'package', 'file', 'pc', 'algorithm'],\n",
       " ['computer', 'package', 'card', 'pc', 'algorithm'],\n",
       " ['computer', 'package', 'pc', 'card', 'file'],\n",
       " ['computer', 'algorithm', 'pc', 'package', 'address.']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sce.top_k_words_all_masks(k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer',\n",
       " 'package',\n",
       " 'file',\n",
       " 'card',\n",
       " 'pc',\n",
       " 'algorithm',\n",
       " 'polygon',\n",
       " 'graphics',\n",
       " 'anybody',\n",
       " 'wanted:']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sce.top_k_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2. LR=0.1, lambda_coef=0.05, mu_coef=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sce2 = TextSCE(net, target_class=0, index2word=index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] Cost: 318.3843688964844 [318.3843688964844, 0.0, 0.0]\n",
      "[5/30] Cost: 301.8505554199219 [293.4259033203125, 8.197685241699219, 0.2269568145275116]\n",
      "[10/30] Cost: 283.6103210449219 [266.95635986328125, 16.152647018432617, 0.5013245344161987]\n",
      "[15/30] Cost: 258.5602111816406 [233.5675811767578, 24.107776641845703, 0.88484787940979]\n",
      "[20/30] Cost: 234.97317504882812 [200.9049530029297, 32.87041473388672, 1.197807788848877]\n",
      "[25/30] Cost: 212.79661560058594 [170.45352172851562, 40.885311126708984, 1.4577829837799072]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlexplain.sce.text_sce.TextSCE at 0x7fe8258eb160>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sce2.fit(X_class_0, lambda_coef=0.05, mu_coef=1.0, n_iter=30, verbose_every_iterations=5, lr=0.1, force_masks_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['computer', 'package', 'file', 'card', 'graphics'],\n",
       " ['computer', 'package', 'file', 'card', 'pc'],\n",
       " ['computer', 'package', 'file', 'card', 'pc'],\n",
       " ['computer', 'package', 'card', 'file', 'pc'],\n",
       " ['computer', 'package', 'card', 'file', 'pc'],\n",
       " ['computer', 'package', 'card', 'file', 'anybody'],\n",
       " ['computer', 'package', 'file', 'card', 'pc'],\n",
       " ['computer', 'package', 'card', 'pc', 'file'],\n",
       " ['computer', 'package', 'card', 'file', 'pc'],\n",
       " ['computer', 'package', 'pc', 'card', 'file']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sce2.top_k_words_all_masks(k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer',\n",
       " 'package',\n",
       " 'card',\n",
       " 'file',\n",
       " 'pc',\n",
       " 'algorithm',\n",
       " 'polygon',\n",
       " 'anybody',\n",
       " 'graphics',\n",
       " 'polygons']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sce2.top_k_words(k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3. Top-10 words to remove. LR=0.1, lambda_coef=0.05, mu_coef=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class 0\n",
      "[0/30] Cost: 318.3843688964844 [318.3843688964844, 0.0, 0.0]\n",
      "[10/30] Cost: 283.6103210449219 [266.95635986328125, 16.152647018432617, 0.5013245344161987]\n",
      "[20/30] Cost: 234.97317504882812 [200.9049530029297, 32.87041473388672, 1.197807788848877]\n",
      "Processing class 1\n",
      "[0/30] Cost: 89.43406677246094 [89.43406677246094, 0.0, 0.0]\n",
      "[10/30] Cost: 27.00507354736328 [2.5235981941223145, 23.599483489990234, 0.881991982460022]\n",
      "[20/30] Cost: -0.7504318952560425 [-37.98480987548828, 35.86570358276367, 1.368674397468567]\n",
      "Processing class 2\n",
      "[0/30] Cost: 279.2134704589844 [279.2134704589844, 0.0, 0.0]\n",
      "[10/30] Cost: 210.59249877929688 [185.0362091064453, 24.91416358947754, 0.6421241760253906]\n",
      "[20/30] Cost: 147.4491424560547 [100.28791046142578, 46.16477966308594, 0.9964428544044495]\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "sces = []\n",
    "for target_class in range(3):\n",
    "    print(f\"Processing class {target_class}\")\n",
    "    X_class_target = choose_k_top_elements_softmax(net, X_train, K=10, target_class=target_class)\n",
    "    sce = TextSCE(net, target_class=target_class, index2word=index2word)\n",
    "    sce.fit(X_class_target, lambda_coef=0.05, mu_coef=1.0, n_iter=30, verbose_every_iterations=10, lr=0.1, force_masks_init=False)\n",
    "    sces.append(sce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target class: 0. Top words:\n",
      "['computer', 'package', 'card', 'file', 'pc', 'algorithm', 'polygon', 'anybody', 'graphics', 'polygons']\n",
      "Target class: 1. Top words:\n",
      "['baseball', 'players', 'season', 'stats', 'team', 'rockies', 'steve', 'home', 'mike', 'pitcher']\n",
      "Target class: 2. Top words:\n",
      "['observatory', 'orbit', 'planet', 'sci\\nlines:', 'university]\\noriginal-sender:', '[via', 'isu@vacation.venari.cs.cmu.edu\\ndistribution:', 'planets', '(713)', 'astronomy']\n"
     ]
    }
   ],
   "source": [
    "for target_class, sce in enumerate(sces):\n",
    "    print(f\"Target class: {target_class}. Top words:\")\n",
    "    print(sce.top_k_words(k=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563 From: dpage@ra.csc.ti.com (Doug Page)\n",
      "Subject: Re: Sr-71 in propoganda films?\n",
      "Nntp-Posting-Host: ra\n",
      "Organization: Texas Instruments\n",
      "Distribution: sci\n",
      "Lines: 28\n",
      "\n",
      "In article <1993Apr5.220610.1532@sequent.com>, bigfoot@sequent.com (Gregory Smith) writes:\n",
      "|> mccall@mksol.dseg.ti.com (fred j mccall 575-3539) writes:\n",
      "|> \n",
      "|> >In <1phv98$jbk@access.digex.net> prb@access.digex.com (Pat) writes:\n",
      "|> \n",
      "|> \n",
      "|> >>THe SR-71 stopped being a real secret by the mid 70's.\n",
      "|> >>I had a friend in high school who had a poster with it's picture.\n",
      "|> \n",
      "|> >It was known well before that.  I built a model of it sometime in the\n",
      "|> >mid 60's, billed as YF-12A/SR-71.  The model was based on YF-12A specs\n",
      "|> >and had a big radar in the nose and 8 AAMs in closed bays on the\n",
      "|> >underside of the fuselage.  The description, even then, read \"speeds\n",
      "|> >in excess of Mach 3 at altitudes exceeding 80,000 feet.\"\n",
      "|> \n",
      "|> L.B.J. publically announced the existance of the Blackbird program\n",
      "|> in 1964.\n",
      "\n",
      "\n",
      "He's also the one who dubbed it the SR-71 - it was the RS-71 until LBJ\n",
      "mippselled (sic) it.\n",
      "\n",
      "FWIW,\n",
      "\n",
      "Doug Page\n",
      "\n",
      "***  The opinions are mine (maybe), and don't necessarily represent those  ***\n",
      "***  of my employer.                                                       ***\n",
      "\n",
      "1596 From: MUNIZB%RWTMS2.decnet@rockwell.com (\"RWTMS2::MUNIZB\")\n",
      "Subject: Long Island (was Why use AC at 20kHz for SSF power)\n",
      "X-Added: Forwarded by Space Digest\n",
      "Organization: [via International Space University]\n",
      "Original-Sender: isu@VACATION.VENARI.CS.CMU.EDU\n",
      "Distribution: sci\n",
      "Lines: 21\n",
      "\n",
      "on Date: Fri, 2 Apr 1993 23:19:46 GMT, Edmund Hack <arabia!hack> writes:\n",
      "\n",
      "/In article <1pgdno$3t1@access.digex.net> prb@access.digex.com (Pat) writes:\n",
      "/>\n",
      "/>I always thought GD's  Fighter plants were in Long Island.  \n",
      "/>\n",
      "/No, Northrup has a plant on Long Island.\n",
      "\n",
      "I don't think Northrup ever had a plant on Long Island.  The two main airframe\n",
      "manufacturers there were (Fairchild)/Republic which closed its doors after the\n",
      "T-46 cancellation, and Grumman (which is still hanging on last I time I called).\n",
      "I think Sperry also started there.  If you're ever in the area check out the\n",
      "Cradle of Aviation Museum at Mitchell field (now mostly parking lots behind the\n",
      "Nassau Coliseum and the community college).  Good display of vehicles from Long\n",
      "Island, including a LEM flight article.\n",
      "\n",
      "Disclaimer: Opinions stated are solely my own (unless I change my mind).\n",
      "Ben Muniz     MUNIZB%RWTMS2.decnet@consrt.rockwell.com    w(818)586-3578\n",
      "Space Station Freedom:Rocketdyne/Rockwell:Structural Loads and Dynamics\n",
      "   \"Man will not fly for fifty years\": Wilbur to Orville Wright, 1901\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, x in enumerate(data_train):\n",
    "    if 'sci\\nlines' in x.lower() and 'prb@access.digex.com' in x.lower():\n",
    "        print(idx, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: dpage@ra.csc.ti.com (Doug Page)\n",
      "Subject: Re: Sr-71 in propoganda films?\n",
      "Nntp-Posting-Host: ra\n",
      "Organization: Texas Instruments\n",
      "Distribution: sci\n",
      "Lines: 28\n",
      "\n",
      "In article <1993Apr5.220610.1532@sequent.com>, bigfoot@sequent.com (Gregory Smith) writes:\n",
      "|> mccall@mksol.dseg.ti.com (fred j mccall 575-3539) writes:\n",
      "|> \n",
      "|> >In <1phv98$jbk@access.digex.net> prb@access.digex.com (Pat) writes:\n",
      "|> \n",
      "|> \n",
      "|> >>THe SR-71 stopped being a real secret by the mid 70's.\n",
      "|> >>I had a friend in high school who had a poster with it's picture.\n",
      "|> \n",
      "|> >It was known well before that.  I built a model of it sometime in the\n",
      "|> >mid 60's, billed as YF-12A/SR-71.  The model was based on YF-12A specs\n",
      "|> >and had a big radar in the nose and 8 AAMs in closed bays on the\n",
      "|> >underside of the fuselage.  The description, even then, read \"speeds\n",
      "|> >in excess of Mach 3 at altitudes exceeding 80,000 feet.\"\n",
      "|> \n",
      "|> L.B.J. publically announced the existance of the Blackbird program\n",
      "|> in 1964.\n",
      "\n",
      "\n",
      "He's also the one who dubbed it the SR-71 - it was the RS-71 until LBJ\n",
      "mippselled (sic) it.\n",
      "\n",
      "FWIW,\n",
      "\n",
      "Doug Page\n",
      "\n",
      "***  The opinions are mine (maybe), and don't necessarily represent those  ***\n",
      "***  of my employer.                                                       ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_train[1563])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 4 (robustness for 'comp.graphics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "target_class = 0\n",
    "\n",
    "X_class_target = choose_k_top_elements_softmax(net, X_train, K=10, target_class=target_class)\n",
    "\n",
    "sce_0 = TextSCE(net, target_class=target_class, index2word=index2word)\n",
    "sce_1 = TextSCE(net, target_class=target_class, index2word=index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] Cost: 318.3843688964844 [318.3843688964844, 0.0, 0.0]\n",
      "[10/30] Cost: 235.9352264404297 [235.9352264404297, 0.0, 0.0]\n",
      "[20/30] Cost: 140.813232421875 [140.813232421875, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlexplain.sce.text_sce.TextSCE at 0x7fe8239654a8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sce_0.fit(X_class_target, lambda_coef=0, mu_coef=0, n_iter=30, verbose_every_iterations=10, lr=0.1, force_masks_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/30] Cost: 201.779541015625 [-9.46551513671875, 87.28343963623047, 123.96162414550781]\n",
      "[10/30] Cost: 93.113525390625 [-48.03938293457031, 108.80816650390625, 32.3447380065918]\n",
      "[20/30] Cost: 50.35553741455078 [-107.24150085449219, 125.9161376953125, 31.6809024810791]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlexplain.sce.text_sce.TextSCE at 0x7fe8239654e0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sce_1.fit(X_class_target, lambda_coef=0.05, mu_coef=50.0, n_iter=30, verbose_every_iterations=10, lr=0.1, force_masks_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['computer', 'package', 'file', 'card', 'graphics', 'pc', 'polygon'],\n",
       " ['computer', 'package', 'card', 'file', 'pc', 'algorithm', 'graphics'],\n",
       " ['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'graphics'],\n",
       " ['computer', 'package', 'card', 'file', 'pc', 'algorithm', 'polygon'],\n",
       " ['computer', 'package', 'card', 'file', 'pc', '|\\n', 'packages'],\n",
       " ['computer', 'package', 'card', 'file', 'anybody', 'pc', '|\\n'],\n",
       " ['computer', 'package', 'file', 'pc', 'algorithm', 'card', 'polygon'],\n",
       " ['computer', 'package', 'card', 'pc', 'algorithm', 'file', 'polygon'],\n",
       " ['computer', 'package', 'pc', 'card', 'file', 'address.', 'algorithm'],\n",
       " ['computer', 'algorithm', 'pc', 'package', 'address.', 'file', 'card']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sce_0.top_k_words_all_masks(k=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'polygon'],\n",
       " ['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'polygon'],\n",
       " ['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'polygon'],\n",
       " ['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'polygon'],\n",
       " ['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'polygon'],\n",
       " ['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'polygon'],\n",
       " ['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'polygon'],\n",
       " ['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'polygon'],\n",
       " ['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'polygon'],\n",
       " ['computer', 'package', 'file', 'card', 'pc', 'algorithm', 'polygon']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sce_1.top_k_words_all_masks(k=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

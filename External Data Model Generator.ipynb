{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of all datasets\n",
    "num_datasets = [\"./data/NORM_BCW.csv\", \"./data/NORM_Ecoli.csv\", \"./data/NORM_Iris.csv\", \"./data/NORM_ISOLET.csv\", \"./data/NORM_SDD.csv\", \"./data/NORM_PBC.csv\", \"./data/NORM_CMSC.csv\", \"./data/NORM_MagicGT.csv\", \"./data/NORM_Wine.csv\"]\n",
    "cat_datasets = [\"./data/OH_BalanceScale.csv\", \"./data/OH_CarEvaluation.csv\", \"./data/OH_HayesRoth.csv\", \"./data/OH_Chess.csv\", \"./data/OH_Lenses.csv\", \"./data/OH_Lymphography.csv\", \"./data/OH_Nursery.csv\", \"./data/OH_SoybeanSmall.csv\", \"./data/OH_TicTacToe.csv\"]\n",
    "mix_datasets = [\"./data/OH_NORM_DefaultOfCCC.csv\", \"./data/OH_NORM_StudentPerf.csv\", \"./data/OH_NORM_Adult.csv\", \"./data/OH_NORM_InternetAdv.csv\", \"./data/OH_NORM_StatlogGC.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitter(df, classes):\n",
    "    \n",
    "    # Sets\n",
    "    X_trains = []\n",
    "    X_tests = []\n",
    "    y_trains = []\n",
    "    y_tests = []\n",
    "    \n",
    "    # Iteration for each class\n",
    "    for c in classes:\n",
    "        df_s = df[df['output']==c]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_s.drop(columns=['output']), \n",
    "                                                            df_s['output'], test_size=0.1, random_state=42)\n",
    "        X_trains.append(X_train)\n",
    "        X_tests.append(X_test)\n",
    "        y_trains.append(y_train)\n",
    "        y_tests.append(y_test)\n",
    "    \n",
    "    return pd.concat(X_trains), pd.concat(X_tests), pd.concat(y_trains), pd.concat(y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_models(paths_datasets):\n",
    "    for path_dataset in paths_datasets:\n",
    "        # Generate df\n",
    "        df = pd.read_csv(path_dataset)\n",
    "        \n",
    "        # Get the name of the dataset\n",
    "        ds_name = path_dataset.split('.')[1].split('_')[-1]\n",
    "        \n",
    "        # Get the possible classes of DS\n",
    "        classes = list(df['output'].unique())\n",
    "        \n",
    "        # Split DataFrame to train and test\n",
    "        X_train, X_test, y_train, y_test = data_splitter(df, classes)\n",
    "        \n",
    "        for c in classes:\n",
    "            # The selected class is 0 and all others are 1\n",
    "            y_train = y_train.copy().apply(lambda x: 0 if x==c else 1)\n",
    "            y_test = y_test.copy().apply(lambda x: 0 if x==c else 1)\n",
    "            \n",
    "            # Save model train Data\n",
    "            pd.concat([X_train, y_train], axis=1).to_csv(f'./modeldata/{str(int(c))}_{ds_name}.csv')\n",
    "            \n",
    "            # Save test Data\n",
    "            pd.concat([X_test, y_test], axis=1).to_csv(f'./testdata/{str(int(c))}_{ds_name}.csv')\n",
    "                        \n",
    "            # Create model\n",
    "            model = keras.Sequential(\n",
    "                [layers.Dense(X_train.shape[1]*20, activation=\"relu\", name=\"layer1\"), # For ISOLET, InternetAdv 4,\n",
    "                 layers.Dense(X_train.shape[1]*10  activation=\"relu\", name=\"layer2\"), # For ISOLET, InternetAdv 2\n",
    "                 layers.Dense(X_train.shape[1]*4, activation=\"relu\", name=\"layer3\"),  # For ISOLET, internetAdv 2\n",
    "                 layers.Dense(X_train.shape[1], activation=\"relu\", name=\"layer4\"),    # For ISOLET, internetAdv 1\n",
    "                 layers.Dense(1, activation=\"sigmoid\", name=\"outputLayer\"),\n",
    "                ])\n",
    "            \n",
    "            # Configure callbacks\n",
    "            my_callbacks = [\n",
    "                tf.keras.callbacks.ModelCheckpoint(filepath=f'./tempModels/{str(int(c))}_{ds_name}_model.temp.h5'),\n",
    "                tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "            ]\n",
    "            \n",
    "            # Configure optimizer\n",
    "            opt = tf.keras.optimizers.RMSprop(\n",
    "                learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False, name='RMSprop')\n",
    "            \n",
    "            # Compile\n",
    "            model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "            \n",
    "            # Train\n",
    "            model.fit(X_train, y_train, epochs=200, callbacks=my_callbacks)\n",
    "            \n",
    "            #Get Accuracies\n",
    "            train_acc = (pd.DataFrame(model.predict(X_train))[0].map(round)==y_train.reset_index(drop=True)).sum()/X_train.shape[0]\n",
    "            test_acc = (pd.DataFrame(model.predict(X_test))[0].map(round)==y_test.reset_index(drop=True)).sum()/X_test.shape[0]\n",
    "            \n",
    "            print(f\"\\n\\nModel for {ds_name}:\\nTrain Accuracy:{train_acc}\\nTest Accuracy:{test_acc}\\nClass Balance={y_train.sum()/y_train.shape[0]}\\n\\n\")\n",
    "            \n",
    "            # Save\n",
    "            model.save(\"./models/\"+str(int(c))+\"_\"+ds_name+\".h5\")\n",
    "            \n",
    "            # Release GPU memory\n",
    "            tf.keras.backend.clear_session()\n",
    "            del model\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models for numerical datasets\n",
    "generate_models(num_datasets)\n",
    "# Create models for categorical datasets\n",
    "generate_models(cat_datasets)\n",
    "# Create models for mixed datasets\n",
    "generate_models(mix_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of all datasets\n",
    "num_datasets = [\"./data/NORM_BCW.csv\", \"./data/NORM_Ecoli.csv\", \"./data/NORM_Iris.csv\", \"./data/NORM_ISOLET.csv\", \"./data/NORM_SDD.csv\", \"./data/NORM_PBC.csv\", \"./data/NORM_CMSC.csv\", \"./data/NORM_MagicGT.csv\", \"./data/NORM_Wine.csv\"]\n",
    "cat_datasets = [\"./data/OH_BalanceScale.csv\", \"./data/OH_CarEvaluation.csv\", \"./data/OH_HayesRoth.csv\", \"./data/OH_Chess.csv\", \"./data/OH_Lenses.csv\", \"./data/OH_Lymphography.csv\", \"./data/OH_Nursery.csv\", \"./data/OH_SoybeanSmall.csv\", \"./data/OH_TicTacToe.csv\"]\n",
    "mix_datasets = [\"./data/OH_NORM_DefaultOfCCC.csv\", \"./data/OH_NORM_StudentPerf.csv\", \"./data/OH_NORM_Adult.csv\", \"./data/OH_NORM_InternetAdv.csv\", \"./data/OH_NORM_StatlogGC.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitter(df, classes):\n",
    "    \n",
    "    # Sets\n",
    "    X_trains = []\n",
    "    X_tests = []\n",
    "    y_trains = []\n",
    "    y_tests = []\n",
    "    \n",
    "    \n",
    "    # Iteration for each class\n",
    "    for c in classes:\n",
    "        df_s = df[df['output']==c]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_s.drop(columns=['output']), \n",
    "                                                            df_s['output'], test_size=0.2, random_state=42)\n",
    "        X_trains.append(X_train)\n",
    "        X_tests.append(X_test)\n",
    "        y_trains.append(y_train)\n",
    "        y_tests.append(y_test)\n",
    "    \n",
    "    return pd.concat(X_trains), pd.concat(X_tests), pd.concat(y_trains), pd.concat(y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_models(paths_datasets):\n",
    "    for path_dataset in paths_datasets:\n",
    "        # Generate df\n",
    "        df = pd.read_csv(path_dataset)\n",
    "        \n",
    "        # Define the majority class as 0 and the other classes as 1\n",
    "        most_common_class = df['output'].value_counts().index[0]\n",
    "        df['output'] = df['output'].apply(lambda x: 0 if x==most_common_class else 1)\n",
    "        \n",
    "        # Get the name of the dataset\n",
    "        ds_name = path_dataset.split('.')[1].split('_')[-1]\n",
    "        \n",
    "        # Get the possible classes of DS\n",
    "        classes = list(df['output'].unique())\n",
    "        \n",
    "        # Split DataFrame to train and test\n",
    "        X_train, X_test, y_train, y_test = data_splitter(df, classes)\n",
    "            \n",
    "                \n",
    "        # Make y multiclass\n",
    "        y_train = pd.concat([y_train, y_train.map({0:1, 1:0})], axis=1)\n",
    "        y_test = pd.concat([y_test, y_test.map({0:1, 1:0})], axis=1)\n",
    "\n",
    "        # Save model train Data indexes\n",
    "        pd.DataFrame(y_train.index).rename(columns={0: 'index'}).to_csv(f'./idxstrain/{ds_name}.csv', index=False)\n",
    "\n",
    "        # Save test Data indexes\n",
    "        pd.DataFrame(y_test.index).rename(columns={0: 'index'}).to_csv(f'./idxstest/{ds_name}.csv', index=False)\n",
    "\n",
    "\n",
    "        # GridSearch Parameters\n",
    "        learning_rates = [0.01, 0.001, 0.0001]\n",
    "        epoch_numbers = [50, 100, 500]\n",
    "        nn_sizes = []\n",
    "        for i in range(1, 6):\n",
    "            nnsize = int((X_train.shape[1]*2+1)*i/5)\n",
    "            if nnsize not in nn_sizes:\n",
    "                nn_sizes.append(nnsize)\n",
    "        parameters = [learning_rates, epoch_numbers, nn_sizes]\n",
    "        comb_param = list(itertools.product(*parameters))\n",
    "\n",
    "        # best scores placeholders\n",
    "        best_model = []\n",
    "        best_params = []\n",
    "        best_f1 = 0.0\n",
    "\n",
    "        for params in comb_param:\n",
    "\n",
    "            lr = params[0]\n",
    "            epoch = params[1]\n",
    "            nn_size = params[2]\n",
    "\n",
    "\n",
    "            # Create model\n",
    "            model = keras.Sequential(\n",
    "                [layers.Dense(nn_size, activation=\"relu\", name=\"layer1\"),\n",
    "                 layers.Dense(2, activation=\"softmax\", name=\"outputLayer\"),\n",
    "                ])\n",
    "\n",
    "            # Configure optimizer\n",
    "            opt = tf.keras.optimizers.RMSprop(learning_rate=lr, name='RMSprop')\n",
    "\n",
    "            # Compile\n",
    "            model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "            # Train\n",
    "            model.fit(X_train, y_train, epochs=epoch, verbose=0)\n",
    "\n",
    "            # Get Prediction for train and test set\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "            #Get Accuracies\n",
    "            train_acc = accuracy_score(np.apply_along_axis(np.argmax, 1, y_train), np.apply_along_axis(np.argmax, 1, y_train_pred))\n",
    "            test_acc = accuracy_score(np.apply_along_axis(np.argmax, 1, y_test), np.apply_along_axis(np.argmax, 1, y_test_pred))\n",
    "\n",
    "            print(f\"\\n\\nModel for {ds_name}:\\nTrain Accuracy:{train_acc}\\nTest Accuracy:{test_acc}\\nClass Balance={y_train.sum()/y_train.shape[0]}\\n\\n\")\n",
    "\n",
    "\n",
    "            # Calculate F1 score for Train Test\n",
    "            f1train = f1_score(np.apply_along_axis(np.argmax, 1, y_train), np.apply_along_axis(np.argmax, 1, y_train_pred))\n",
    "            f1s = f1_score(np.apply_along_axis(np.argmax, 1, y_test), np.apply_along_axis(np.argmax, 1, y_test_pred))\n",
    "\n",
    "            # Report f1 for the params\n",
    "            with open('./all_params.txt', 'a') as f:\n",
    "                f.write(f'{ds_name} {f1s} {params} \\n')\n",
    "\n",
    "            if f1s > best_f1 and f1train > 0:\n",
    "                best_f1 = f1s\n",
    "                best_model = model\n",
    "                best_params = params\n",
    "                \n",
    "            # Release GPU memory\n",
    "            tf.keras.backend.clear_session()\n",
    "            del model\n",
    "\n",
    "        # Report the best params and f1 score for the dataset and class\n",
    "        with open('./best_params.txt', 'a') as f:\n",
    "            f.write(f'{ds_name} {best_f1} {best_params} \\n')\n",
    "\n",
    "        # Save\n",
    "        best_model.save(\"./models/\"+ds_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models for numerical datasets\n",
    "generate_models(num_datasets)\n",
    "# Create models for categorical datasets\n",
    "generate_models(cat_datasets)\n",
    "# Create models for mixed datasets\n",
    "generate_models(mix_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
